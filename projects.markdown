---
layout: default
title: Projects
menu: yes
---

*Spring 2018*

We want you to get your hands dirty with most of the core topics covered in the course. 
To that end, we prepared two projects. 

Groups: check Blackboard or our blog posts.

# Project 1 

*From TBA*

In this project you will learn about lexical alignment, the task of learning correspondences between words in different languages.
You will apply latent variable modelling techniques, in particular, learning with directed graphical models (aka locally normalised models).
In this project, you will parameterise the model using categorical distributions. 
You will experiment with maximum likelihood estimation and Bayesian modelling with Dirichlet priors.

* Maximum likelihood estimation for IBM1: EM algorithm
* Bayesian estimation for IBM1: variational Bayes

Resources:

* [Project description](resources/project_ibm/project1.pdf)
* [Training data](resources/project_ibm/training.tgz)
* [Validation data](resources/project_ibm/validation.tgz)
[comment]: # * [Test data](resources/project_ibm/testing.tgz)  ``new!``
* [Tips](https://uva-slpl.github.io/nlp2/project1/2017/04/12/IBM.html)
* [Helper functions for validation AER](resources/project_ibm/aer.py)
    * Note that I wrote this helper class using `python3`, if you are using `python2` you will need to import `from __future__ import division` to avoid the default integer division (whereby stuff like 1/2 evaluates to 0 instead of 1.5)

Submission:

TBA

Assessment: [guidelines](assessment) /  grades on blackboard.


# Project 2 

*TBA*


