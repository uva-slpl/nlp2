\section{Introduction}

\frame{
	\frametitle{Recap}
	We looked into Alignment a directional word-based model.
	\begin{itemize}
	\item Parametrisation: Categorical.
	\item Estimation techniques: EM vs VB.
	\end{itemize}
	\pause
	We have not look into generation:
	\begin{itemize}
	\item No model of length
 	\item No model of segmentation
 	\item Bad model for translation
	\end{itemize}

}

\frame{
	\frametitle{Translation}

	Model:

	$$P(E|F) = \frac{P(E)P(F|E)}{P(F)}$$

	Prediction:

	$$\hat{E} = \argmax_E P(E)P(F=f|E)$$

	Estimation:

	\begin{itemize}
		\item $P(E)$ $n$-gram LM.
		\item $P(F|E)$ TM.
	\end{itemize}

}

\frame{
	\frametitle{Word-based SMT}
	\citep{Brown+1993:smt}\\
	\begin{center}
	\includegraphics[scale=0.5]{"img/wbmt"}
	\end{center}
	\begin{footnotesize}
	Figure: \citet{Koehn:2010:SMT}
	\end{footnotesize}
	

}

\frame{
	\frametitle{Limitations of word-based approach}

	Linguistically
	\begin{itemize}
		\item Can not translate many-to-one or many-to-many
		\item Compositionality of translation\\
			multi-word / idiomatic expressions.
	\end{itemize}

	~

	Computationally during prediction
	\begin{itemize}
		\item $n!$ permutations in decoding.
	\end{itemize}
}


\frame{
	\frametitle{Phrase-based model}
	Change of units: phrase.\\
	\begin{center}
	\includegraphics[scale=0.5]{"img/phrase-model-alignment"}
	\end{center}
	\begin{footnotesize}
	Figure: \citet{Koehn:2010:SMT}
	\end{footnotesize}
}


\frame{
	\frametitle{Phrase-based model}

	Phrase pairs as translation units
	\begin{itemize}
		\item Capture non-compositional translations.
		\item Exploit (local) reordering patterns.
	\end{itemize}


}

\frame{
	\frametitle{Illustration}
	\includegraphics[scale=0.5]{"img/PB extraction 2"}

	\pause
	~
	\begin{center}
	\begin{tabular}{l  r}

		J'$_1$ ai$_2$ les$_3$ yeux$_4$ noirs$_5$ & input\\ \pause
		{[\textcolor{blue}{J'$_1$ ai$_2$}] [\textcolor{Green}{les$_3$ yeux$_4$}] [\textcolor{red}{noirs$_5$}]} & segmentation\\ \pause
		{[\textcolor{blue}{J'$_1$ ai$_2$}]$_1$ [\textcolor{red}{noirs$_5$}]$_3$ [\textcolor{Green}{les$_3$ yeux$_4$}]$_2$} & ordering\\		\pause
		{[\textcolor{blue}{I have}]$_1$ [\textcolor{red}{black}]$_3$ [\textcolor{Green}{eyes}]$_2$} & translation \\	\pause
		 &\textbf{Derivation}
	\end{tabular}
	\end{center}
}



\section{Model}
\frame{
    \frametitle{Modelling Derivations}

	\begin{align*}
		P(e,d|f) = \frac{\exp(S_{\theta }(e,d,f))}{\sum_{{e}'}\sum_{{d}'} \exp(S_{\theta}({e}',{d}', f))}
	\end{align*}
	\pause
	Challenging normalisation.\\
	Large space of derivations:\\
	\begin{itemize}
	\item Number of segments.
	\item Number of permutations.
	\item Number of translations.
	\end{itemize}
}

\frame{
    \frametitle{Discriminative classifier}
	\begin{itemize}
	\item Give up on marginalisation of $d$
	\item Give up on probabilistic modelling
	\item How?\pause
	\item If we look at the prediction:
	\end{itemize}
	\begin{align*}
	\hat{e},\hat{d} &= \argmax_{e,d|f} \log P(e,d|f)\\
	&= \argmax_{e,d|f} S_{\theta}(e,d,f) - \underbrace{\log \sum_{{e}'}\sum_{{d}'} \exp(S_{\theta}({e}',{d}', f))}_{\text{constant for any} (e,d | f)}\\
	&= \argmax_{e,d|f} S_{\theta}(e,d,f)
	\end{align*}
	Trained discriminatively (e.g. structured perceptron).
}




\frame{
	\frametitle{Linear model}

	The score function$S_{\theta}$ is defined as a linear model.\\
	$$S_{\theta}(e,d,f) = \theta^T H(e,d,f)$$
	where $\theta$ are parameters\\
	$h$ are feature functions.\\
	\pause
	Linear model decomposes over phrases.\\
	$$S_{\theta}(e,d,f) = \theta^T \sum_{i}^{n} \underbrace{h_i(d_i|e,f)}_{\text{local feature function}}$$
	Model featurises steps in the derivation independently.

}

\frame{
    \frametitle{PBSMT Model}
   
     \begin{itemize}
    \item Feature functions $n=3$
    \item Translation feature function: $$h_1 = \log  P(\bar{f}| \bar{e})$$
    \item Language Model feature function: $$h_2 = \log  P(e|e_{\text{past}})$$
    \item Distortion feature function: $$h_3 = \log  d(\text{start}_k - \text{end}_{k-1} - 1)$$
    \end{itemize}

}


\frame{
	\frametitle{Phrase pairs from word alignments}

	%\citet{Koehn+2003:PBSMT}
	\only<1>{
		\includegraphics[scale=0.5]{"img/PB extraction 0"}
	}
	\only<2>{
		\includegraphics[scale=0.5]{"img/PB extraction 1"}
	}
	\only<3>{
		\includegraphics[scale=0.5]{"img/PB extraction 1b"}
	}
	\only<4>{
		\includegraphics[scale=0.5]{"img/PB extraction 2"}
	}
	\only<5>{
		\includegraphics[scale=0.5]{"img/PB extraction 2b"}
	}
	\only<6>{
		\includegraphics[scale=0.5]{"img/PB extraction 3"}
	}
	\only<7>{
		\includegraphics[scale=0.5]{"img/PB extraction 4"}
	}
	\only<8>{
		\includegraphics[scale=0.5]{"img/PB extraction 5"}
	}
	\only<9>{
		\includegraphics[scale=0.5]{"img/PB extraction all"}
	}


	\begin{itemize}
		\item<2-> multiple derivations can explain an ``observed'' phrase pair \\
		\item<9> we extract all of them once, irrespective of derivation
	\end{itemize}
}


\frame{
    \frametitle{Phrase Table}
    \begin{itemize}
    \item Goal: Learn phrase translation table from parallel corpus.
	\pause
    \item Three stages:
    \item Word alignment given IBM.
    \item Extraction of phrase pairs.
    \item Phrase scoring.

    \end{itemize}

}


\frame{
	\frametitle{Phrase extraction}
				Let $(\bar{f},\bar{e})$ be a phrase pair\\
				Let $A$ be an alignment matrix\\
				\pause
				\begin{block}{$(\bar{f},\bar{e})$ consistent with $A$ if, and only if:}
					\begin{itemize}
						\pause
						\item Words in $\bar{f}$, if aligned, align only with words in $\bar{e}$\\
						\pause
						\begin{tiny}
						\begin{columns}
						\begin{column}{1cm}
						\begin{tabular}{|p{0.1cm}|p{0.1cm}|p{0.1cm}|}
							\multicolumn{3}{c}{\cblue{C}} \\ \hline
							\cellg $\bullet$ & \cellg & \cellg \\ \hline
							\cellg & \cellg $\bullet$ & \cellg $\bullet$ \\ \hline
							 &  & \\ \hline
						\end{tabular}
						\end{column}
						\begin{column}{1cm}
						\begin{tabular}{|p{0.1cm}|p{0.1cm}|p{0.1cm}|}
							\multicolumn{3}{c}{\cblue{C}} \\ \hline
							\cellg $\bullet$ & \cellg & \cellg \\ \hline
							\cellg & \cellg $\bullet$ & \cellg $\bullet$ \\ \hline
							\cellg & \cellg & \cellg \\ \hline
						\end{tabular}
						\end{column}
						\begin{column}{1cm}
						\begin{tabular}{|p{0.1cm}|p{0.1cm}|p{0.1cm}|}
							\multicolumn{3}{c}{\cred{I}} \\ \hline
							\cellg $\bullet$ & \cellg & \\ \hline
							\cellg & \cellg $\bullet$ & \textcolor{red}{$\bullet$} \\ \hline
							 &  & \\ \hline
						\end{tabular}
						\end{column}
						\end{columns}
						\end{tiny}

						\pause
						\item Words in $\bar{e}$, if aligned, align only with words in $\bar{f}$\\
						\pause
						\begin{tiny}
						\begin{columns}
						\begin{column}{1cm}
						\begin{tabular}{|p{0.1cm}|p{0.1cm}|p{0.1cm}|}
							\multicolumn{3}{c}{\cblue{C}} \\ \hline
							\cellg $\bullet$ & \cellg & \\ \hline
							\cellg & \cellg $\bullet$ & \\ \hline
							\cellg & \cellg $\bullet$ & \\ \hline
						\end{tabular}
						\end{column}
						\begin{column}{1cm}
						\begin{tabular}{|p{0.1cm}|p{0.1cm}|p{0.1cm}|}
							\multicolumn{3}{c}{\cblue{C}} \\ \hline
							\cellg $\bullet$ & \cellg & \cellg \\ \hline
							\cellg & \cellg $\bullet$ & \cellg \\ \hline
							\cellg & \cellg $\bullet$ & \cellg \\ \hline
						\end{tabular}
						\end{column}
						\begin{column}{1cm}
						\begin{tabular}{|p{0.1cm}|p{0.1cm}|p{0.1cm}|}
							\multicolumn{3}{c}{\cred{I}} \\ \hline
							\cellg $\bullet$ & \cellg & \\ \hline
							\cellg & \cellg $\bullet$ & \\ \hline
							 & \textcolor{red}{$\bullet$} & \\ \hline
						\end{tabular}
						\end{column}
						\end{columns}
						\end{tiny}

						\pause
						\item $(\bar{f},\bar{e})$ must contain at least one alignment point\\
						\pause
						\begin{tiny}
						\begin{columns}
						\begin{column}{1cm}
						\begin{tabular}{|p{0.1cm}|p{0.1cm}|p{0.1cm}|}
							\multicolumn{3}{c}{\cblue{C}} \\ \hline
							\cellg $\bullet$ & \cellg & \cellg \\ \hline
							\cellg  &\cellg $\bullet$ & \cellg \\ \hline
							\cellg  & \cellg & \cellg \\ \hline
						\end{tabular}
						\end{column}
						\begin{column}{1cm}
						\begin{tabular}{|p{0.1cm}|p{0.1cm}|p{0.1cm}|}
							\multicolumn{3}{c}{\cblue{C}} \\ \hline
							\cellg $\bullet$ & & \\ \hline
							  & \cellg $\bullet$ & \cellg \\ \hline
							 & \cellg & \cellg \\ \hline
						\end{tabular}
						\end{column}
						\begin{column}{1cm}
						\begin{tabular}{|p{0.1cm}|p{0.1cm}|p{0.1cm}|}
							\multicolumn{3}{c}{\cred{I}} \\ \hline
							$\bullet$ &  & \\ \hline
							 & $\bullet$ & \\ \hline
							 &  & \cellg \\ \hline
						\end{tabular}
						\end{column}
						\end{columns}
						\end{tiny}

					\end{itemize}
				\end{block}

}

\frame{
	\frametitle{Feature Translation Model}
	Features $$\log  P(\bar{f}| \bar{e})$$ and $$\log  P(\bar{e}| \bar{f})$$\\
	Number of times a (consistent) phrase pair is ``observed''\\
	$$c(\bar{f}, \bar{e})$$

	Relative frequency counting
	$$\varphi(\bar{f}|\bar{e}) = \frac{c(\bar{f}, \bar{e})}{\sum_{\bar{f}'} c(\bar{f}', \bar{e})}$$
	
	

}

\begin{comment}
\frame{
	\frametitle{Feature Distortion}
	Feature $$h_3 = \log  d(\text{start}_k - \text{end}_{k-1} - 1)$$\\
	Example

	\begin{center}
	\begin{tabular}{| l | l | p{1cm} | p{1cm} | p{1cm} | p{1cm} |}
	\hline
	& & \textcolor{red}{I} & \textcolor{red}{have} & \textcolor{red}{black} & \textcolor{red}{eyes} \\ \hline
	\textcolor{gray}{1}& \textcolor{blue}{J'} & \multicolumn{2}{c|}{\multirow{2}{*}{1}}  & & \\ \cline{1-2}\cline{5-6}
	\textcolor{gray}{2}& \textcolor{blue}{ai} & \multicolumn{2}{c|}{} & & \\ \hline
	\textcolor{gray}{3}& \textcolor{blue}{les} & & & & \multicolumn{1}{c|}{\multirow{2}{*}{3}} \\ \cline{1-5}
	\textcolor{gray}{4}& \textcolor{blue}{yeux} & & & &  \\ \hline
	\textcolor{gray}{5}& \textcolor{blue}{noirs} & & & \multicolumn{1}{c|}{2} & \\ \hline
	\end{tabular}
	\end{center}

	\begin{columns}

	\begin{column}{0.3\textwidth}
	\begin{itemize}
		\item $\bar{f}_1 = \textcolor{blue}{\text{J' ai}}$
		\item $\bar{e}_1 = \textcolor{red}{\text{I have}}$
		\item $\text{start}_1 = 1$
		\item $\text{end}_1 = 2$
	\end{itemize}
	\end{column}
	\begin{column}{0.3\textwidth}
	\begin{itemize}
		\item $\bar{f}_2 = \textcolor{blue}{\text{noirs}}$
		\item $\bar{e}_2 = \textcolor{red}{\text{black}}$
		\item $\text{start}_2 = 5$
		\item $\text{end}_2 = 5$
	\end{itemize}
	\end{column}
	\begin{column}{0.3\textwidth}
	\begin{itemize}
		\item $\bar{f}_3 = \textcolor{blue}{\text{les yeux}}$
		\item $\bar{e}_3 = \textcolor{red}{\text{eyes}}$
		\item $\text{start}_3 = 3$
		\item $\text{end}_3 = 4$
	\end{itemize}
	\end{column}

	\end{columns}
}
\end{comment}

\frame{
	\frametitle{Feature Language Model}
	Feature n-gram language model $$\log  P(e|e_{\text{past}})$$\\
	Estimated independently on monolingual data.
	\begin{center}
	\includegraphics[scale=0.3]{"img/Unigram"}
	\end{center}
	
	\begin{footnotesize}
	http://recognize-speech.com/images/Antonio/Unigram.png
	\end{footnotesize}
}

%\frame{
%	\frametitle{Feature Segmentation}


%}




\section{Prediction}


\frame{
	\frametitle{Translation Options}

	\begin{itemize}
	\item Europarl phrase table: 2727 matching phrase pairs for a sentence.
	\item Search problem with beam search:
	\begin{enumerate}
	\item From phrase translation table for all input phrases.
	\item Initial hypothesis: no input words covered, no output produced.
	\item Pick any translation option, create new hypothesis.
	%\item Create hypotheses for all other translation options
	\item Expand hypotheses from created partial hypothesis.
	\item Backtrack from highest scoring complete hypothesis.
	\end{enumerate}
	\end{itemize}

}



\frame{
	\frametitle{Decoding}
	\begin{center}
	\includegraphics[scale=0.3]{"img/beam_search"}
	\end{center}
	\begin{footnotesize}
	Figure: \citet{Koehn:2010:SMT}
	\end{footnotesize}
	

}



