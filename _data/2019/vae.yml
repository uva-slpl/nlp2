-
  layout: lecture
  selected: y
  date: 2019-04-18
  img: dgm 
  uid: dgm
  title: "Probabilistic modelling for NLP"
  instructor:
  abstract: "This lecture presents probabilistic modelling with neural networks, we will start with maximum likelihood estimation based on fully observed data, then we will discuss the challenges of learning distributions over observed and unobserved (latent) data. We will then talk about variational inference and how it may help us estimate deep generative models."
  background:
    - "[Neural Variational Inference and Learning in Belief Networks](https://arxiv.org/pdf/1402.0030.pdf)"
    - "Variational Inference: "
    - "Chapter 2 of Matthew Beal's [PhD thesis](http://www.cse.buffalo.edu/faculty/mbeal/papers/beal03.pdf) gives a very clear development of variational inference for Bayesian models."
    - "An outstanding account of variational methods with lots of references to recent developments is given in David Blei's [tutorial](https://arxiv.org/pdf/1601.00670.pdf)."
  further:
  slides: resources/slides/dgm4nlp.pdf
  video:
    - "[Videovi](https://webcolleges.uva.nl/Mediasite/Play/d8fb24d74122414c9e38743eb30387201d)"
  
-
  layout: lecture
  selected: y
  date: 2019-04-25
  img: vae_1
  uid: vae
  title: "Variational auto-encoders"
  instructor: 
  abstract:  "This lecture will present the variational auto-encoder, an important deep generative model that makes a building block for many others. We will also learn about the reparameterised gradient, a major development for efficient estimation of DGMs."
  background:
    - "[Gaussian distribution](https://en.wikipedia.org/wiki/Normal_distribution)"
    - "The original: [Kingma and Welling (2014)](https://arxiv.org/abs/1312.6114) and [Rezend et al (2014)](https://arxiv.org/abs/1401.4082)"
  further:
    - "Variational auto-encoders:"
    - "A [tutorial](https://arxiv.org/abs/1606.05908) (`disclaimer:` not my favourite!)"
    - "More on reparameterisation (`advanced!`): [Titsias and Lazaro-Gredilla (2014)](http://www2.aueb.gr/users/mtitsias/papers/titsias14.pdf) and [Ruiz et al (2016)](https://arxiv.org/abs/1610.02287)"
    - "[Automatic Differentiation Variational Inference](https://arxiv.org/pdf/1603.00788.pdf)"
  slides: resources/slides/dgmvae.pdf
  video:
    - "[Videovae](https://webcolleges.uva.nl/Mediasite/Play/f2b63ac0d08e4ec5b8ceddac366de44f1d)"
  

  
-
  layout: lecture
  selected: y
  date: 2019-04-29
  img: embedalign
  uid: worddgms
  title: "Generative models of word representation"
  instructor: 
  abstract:  "This lecture will present deep latent variable models of word representation"
  background:
    - "CBOW and Skip-gram: [Distributed Representations of Words and Phrases and their Compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)"
    - "Skip-gram is a binary classifier: [word2vec Explained: Deriving Mikolov et al.â€™s Negative-Sampling Word-Embedding Method](https://arxiv.org/pdf/1402.3722.pdf)"
    - "Generative modelling via lexical alignment: [Learning Bilingual Word Representations by Marginalizing Alignments](http://acl2014.org/acl2014/P14-2/pdf/P14-2037.pdf)"
  further:
    - "[Embedding Words as Distributions with a Bayesian Skip-gram Model](https://arxiv.org/pdf/1711.11027)"
    - "[Deep Generative Model for Joint Alignment and Word Representation](https://arxiv.org/pdf/1802.05883.pdf)"
  discussion:
    - "[Auto-encoding variational inference for topic models](https://arxiv.org/pdf/1703.01488.pdf)"
    - "[Semantic Parsing with Semi-Supervised Sequential Autoencoders](https://arxiv.org/pdf/1609.09315.pdf)"
  slides: resources/slides/dgmembed.pdf
  video:
    - "[Videoembed](https://webcolleges.uva.nl/Mediasite/Play/389e4ab282c449e8b8dc5e7e595226fd1d)"
  
-
  layout: lecture
  selected: y
  date: 2019-05-02 
  img: sntdgms
  uid: sntdgms
  title: "Generative language models"
  instructor: 
  abstract:  "This lecture will present generative models over natural language sentences."
  background:
    - "[Recurrent neural network based language model](http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf)"
  discussion: 
    - "[Generating Sentences from a Continuous Space](https://arxiv.org/pdf/1511.06349.pdf)"
    - "[Variational neural machine translation](https://arxiv.org/pdf/1605.07869.pdf)"
  slides: resources/slides/dgmlm.pdf
  video:
    - "[Videolm](https://webcolleges.uva.nl/Mediasite/Play/337b96b902dd41998c68d5e12db0f0b81d)"
  
-
  layout: lecture
  selected: y
  date: 2019-05-06
  img: lda
  uid: ldavae
  title: "Probabilistic Topic Models"
  instructor: 
  abstract:  
  background:
    - "[Topic models](http://www.cs.columbia.edu/~blei/papers/BleiLafferty2009.pdf)"
    - "[Neural Variational Inference for Text Processing](https://arxiv.org/pdf/1511.06038.pdf)"
    - "[Discovering Discrete Latent Topics with Neural Variational Inference](https://arxiv.org/pdf/1706.00359.pdf)"
    - "[Autoencoding Variational Inference For Topic Models](https://arxiv.org/pdf/1703.01488.pdf)"
  discussion:
  further:
  slides: resources/slides/dgmtopic.pdf
  code:
  video: "[Videotopic](https://webcolleges.uva.nl/Mediasite/Play/f5774d42cdda47e195c5b6e6fc5e05811d)"
-
  layout: lecture
  selected: y
  date: 2019-05-09
  img: mnmt
  uid: multmt
  title: "Generative models for multimodal machine translation"
  instructor: 
  abstract:  
  background:
    - "[Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)"
    - "[Neural Machine Translation Slides](resources/slides/UvA___NLP2___Neural_Machine_Translation__slides_.pdf)"
  discussion:
  further:
  slides: resources/slides/UvA___NLP2__Using_Images_to_Ground_Machine_Translation__slides_.pdf
  code:
  video:
    - "[Videonmt](https://webcolleges.uva.nl/Mediasite/Play/561eae9167b947999b6d9f56e0c101e91d)"
-
  layout: lecture
  selected: y
  date: 2019-05-13
  img: discretedgms
  uid: rtevae
  title: "Generative models for natural language inference "
  instructor: 
  abstract: 
  background:
  discussion:
  further:
  slides:
  video:
-
  layout: lecture
  selected: y
  date: 2019-05-16
  img: discretedgms
  uid: discretedgms
  title: "Discrete latent variable models"
  instructor: 
  abstract:  "This lecture will present models of whose latent variables are discrete and cannot be exactly marginalised."
  background:
    - "VI without reparameterised gradients: [Neural Variational Inference and Learning in Belief Networks](https://arxiv.org/pdf/1402.0030.pdf)"
    - "Control variates: [MuProp: Unbiased Backpropagation for Stochastic Neural Networks](https://arxiv.org/pdf/1511.05176.pdf)"
  discussion:
    - "[Jointly Learning Sentence Embeddings and Syntax with Unsupervised Tree-LSTMs](https://arxiv.org/pdf/1705.09189.pdf)"
    - "[Learning to Compose Words into Sentences with Reinforcement Learning](https://arxiv.org/pdf/1611.09100.pdf)"
  further:
    - "Investigation of induced latent variables: [Do latent tree learning models identify meaningful structure in sentences?](https://arxiv.org/pdf/1709.01121.pdf)"
    - "No latent variables, but generative training: [Recurrent Neural Network Grammars](https://arxiv.org/pdf/1602.07776.pdf)"
    - "More on gradient estimation: [Simple Statistical Gradient-Flowing Algorithms for Connectionist Reinforcement Learning](https://link.springer.com/content/pdf/10.1007%2FBF00992696.pdf)"
  slides:
  video:
  
-
  layout: lecture
  selected: y
  date: 2019-05-20
  img: end
  uid: end
  title: "Generative models for neural machine translation"
  note: 
  abstract:  
  background:
  discussion:
  code: 
  video:
  data: 
